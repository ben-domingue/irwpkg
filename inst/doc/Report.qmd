---
title: "Report"
format: html
vignette: >
  %\VignetteIndexEntry{Report}
  %\VignetteEngine{quarto::html}
  %\VignetteEncoding{UTF-8}
---


```{r setup}
#| eval: false
library(irwpkg)
library(mirt)
```

# Overview

The [Item Response Warehouse (IRW)](https://datapages.github.io/irw/) is a large-scale database of harmonized item response datasets hosted [here](https://redivis.com/datasets/as2e-cv7jb41fd).

`irwpkg` provides a simple, efficient interface for accessing and analyzing IRW datasets, providing tools for:

1.  **Exploration**: Browse and identify datasets.

2.  **Retrieval**: Fetch datasets into R.

3.  **Reformatting**: Prepare data for psychometric analysis.


# 1. Exploration

Gain insights into the IRW database and find datasets relevant to your analysis using tools for listing, summarizing, and filtering.

- `list_available_datasets()`
- `get_database_metadata()` & `get_table_metadata()`
- `show_overall_statistics()` & `visualize_metadata_distributions()`
- `filter_tables()`


## List Available Datasets
Use `list_available_datasets()` to view all datasets and their metadata (names, row counts, variable counts).

```{r}
#| eval: false
datasets <- list_available_datasets()
dim(datasets)
head(datasets)

```

## Database Metadata
Retrieve high-level metadata for the entire database using `get_database_metadata()`:
```{r}
#| eval: false
db_info <- get_database_metadata()
```

## Database Metadata (cont.)
You can also get metadata about individual datasets using `get_table_metadata()`:
```{r}
#| eval: false
table_info <- get_table_metadata("lessR_Mach4")
```

## Overall Statistics
View statistical summaries for key dataset attributes with `show_overall_statistics()`:

```{r}
#| eval: false
show_overall_statistics()
```

## Overall Statistics (cont.)
Use `visualize_metadata_distributions()` to generate histograms of dataset attributes.

```{r}
#| eval: false
visualize_metadata_distributions()
```

## Overall Statistics (cont.)
Specify custom ranges for attributes if needed:
```{r}
#| eval: false
visualize_metadata_distributions(ranges = list(
  id_count = c(0, 10000),
  resp_count = c(0, 100000),
  item_count = c(0, 150),
  density = c(0, 2)
))
```


## Filter Datasets by Criteria
Retrieve datasets that match specific numeric ranges of key attributes:

```{r}
#| eval: false
matching_tables <- filter_tables(
  id_count = c(100, 1000), 
  density = c(0.1, 0.5))
print(matching_tables)
```

## Filter Datasets by Criteria (cont.)

Filter datasets that include specific columns (`date`, `rt`, or `rater`):

```{r}
#| eval: false
matching_tables <- filter_tables(has_rater = TRUE)

print(matching_tables)
```
## Filter Datasets by Criteria (cont.)
You can combine multiple criteria to refine your search:

```{r}
#| eval: false
matching_tables <- filter_tables(
  id_count = c(100, 10000), 
  has_rater = TRUE
)
print(matching_tables)
```


# 2. Retrieval
Once youâ€™ve identified the desired datasets, fetch them into R for analysis.

- `fetch_data()`
- `download_data()`

## Fetch a single dataset
Use `fetch_data()` to retrieve a single dataset:
```{r}
#| eval: false
swmd_mokken <- fetch_data(name = "swmd_mokken")
str(swmd_mokken)

```

## Fetch multiple datasets
Retrieve multiple datasets by providing their names:
```{r}
#| eval: false
datasets <- fetch_data(c("fractals_rating", "spelling2pronounce_edwards2023"))
print(names(datasets))
str(datasets$fractals_rating)

```

## Fetch multiple datasets (cont.)
Alternatively, you can use the output of `filter_tables()` directly:

```{r}
#| eval: false
matching_tables <- filter_tables(has_rater = TRUE)
datasets <- fetch_data(matching_tables)
print(names(datasets))
```

## Download datasets
Save datasets locally with `download_data()`:

```{r}
#| eval: false
download_data("swmd_mokken", path = "mydata.csv", overwrite=TRUE)
```

# 3. Reformatting
Reformat IRW data for analysis with popular psychometric tools.

- `irw_rename()`
- `reformat()`

## Rename IRW Variables
Use `irw_rename()` to rename IRW variables for consistency.
Similar to but less flexible than `janitor::clean_names()`, it can handle character vectors or any object with names and standardize them.

```{r}
#| eval: false
test_vec <- c("InTeREsTiNG.VAR", "another.VAR", "this.$&^!_VAR")
irw_rename(test_vec)
```


## Example item information workflow
Fetch a dataset, reformat it, and analyze item information functions using `mirt`:

```{r}
#| eval: false
df <- fetch_data(name = "lessR_Mach4")
rdf = reformat(df)
mirtmod = mirt::mirt(rdf)
plot(mirtmod, type="infotrace")
```

```{r}
#| eval: false
summary(mirtmod)
```



## Example nonparametric IRT item workflow
Fetch a dataset, reformat it, and analyze to check for item monotonicity using `mokken`:

```{r}
#| eval: false
df <- fetch_data(name = "NAMPRB_Siwiak_2024_AOT")
rdf = reformat(df, package = "mokken")
mokmod = mokken::check.monotonicity(rdf)
plot(mokmod, ask=FALSE)
```

```{r}
#| eval: false
summary(mokmod)
```

## Example omega reliability analysis workflow based item response times
Fetch a dataset, reformat it, and analyze it with `psych` function `omega` for factor analysis:

```{r}
#| eval: false
df <- fetch_data(name = "dd_rotation")
rdf = reformat(df, package = "psych", resp = "rt")
famod = psych::omega(rdf)
plot(famod)
summary(famod)
```

## Example exploratory factor analysis on longitudinal data
Fetch a dataset, reformat it, and analyze it with `lavaan` function `efa` for factor analysis:

```{r}
#| eval: false
df <- fetch_data(name = "COACH_Chen_2022_ADL")
rdf = reformat(df,package = "lavaan",item=c("item","wave"))
lavmod = lavaan::efa(rdf)
summary(lavmod)
```




